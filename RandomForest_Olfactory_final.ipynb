{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls /content/drive/MyDrive/5features.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.io as sio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print('Importing Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('/content/drive/MyDrive/5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "Normal = data1[:15,:]\n",
    "MCI = data1[15:22,:]\n",
    "AD = data1[22:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from local address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "Normal = data1[:15,:]\n",
    "MCI = data1[15:22,:]\n",
    "AD = data1[22:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, Normal (0) vs MCI (1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [2, 5, 10],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [10, 100, 500, 1000]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.append(Normal,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'n_estimators':[10,100,500,1000],'max_depth':[2, 5, 10], 'min_samples_split':[2,4,8]}\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "clf = GridSearchCV(RF, parameters)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.9\n",
      "0.2\n",
      "balanced_accuracy:\n",
      "0.9\n",
      "0.2\n",
      "precision:\n",
      "0.8666666666666666\n",
      "0.26666666666666666\n",
      "precision macro:\n",
      "0.9333333333333333\n",
      "0.13333333333333336\n",
      "recall:\n",
      "1.0\n",
      "0.0\n",
      "recall macro:\n",
      "0.9333333333333333\n",
      "0.13333333333333336\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(Normal,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, AD (1) vs MCI (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [2, 5, 10],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [10, 100, 500, 1000]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.append(AD,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = abs(train_data[:,num_feature]-2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'n_estimators':[10,100,500,1000],'max_depth':[2, 5, 10], 'min_samples_split':[2,4,8]}\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "clf1 = GridSearchCV(RF, parameters)\n",
    "clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.9\n",
      "0.1224744871391589\n",
      "balanced_accuracy:\n",
      "0.9\n",
      "0.1224744871391589\n",
      "precision:\n",
      "0.8333333333333334\n",
      "0.21081851067789195\n",
      "precision macro:\n",
      "0.9166666666666666\n",
      "0.10540925533894599\n",
      "recall:\n",
      "1.0\n",
      "0.0\n",
      "recall macro:\n",
      "0.9166666666666666\n",
      "0.10540925533894599\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(AD,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = abs(train_data[:,num_feature]-2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest (Normal(0) vs MCI (1) + MCI (1) vs AD (2)) with 5 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50385714 0.6009881  0.29416667]\n",
      " [0.93575758 0.06003788 0.94416667]\n",
      " [0.98575758 0.02212121 0.97      ]\n",
      " [0.07052381 0.91557143 0.09833333]\n",
      " [0.15719048 0.8647381  0.11333333]\n",
      " [0.91575758 0.04670455 0.99083333]\n",
      " [0.53711472 0.51935931 0.42416667]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[1 2 0 1 1 2 0]\n",
      ">acc=0.611\n",
      "[[0.79       0.115      0.98      ]\n",
      " [0.845      0.0875     0.98      ]\n",
      " [0.33777778 0.77744444 0.10733333]\n",
      " [0.71111111 0.41077778 0.46733333]\n",
      " [0.62777778 0.47944444 0.41333333]\n",
      " [0.83       0.09       0.99      ]\n",
      " [0.81527778 0.52069444 0.14333333]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[2 2 1 0 0 2 0]\n",
      ">acc=0.167\n",
      "[[0.94833333 0.13977778 0.77211111]\n",
      " [0.99833333 0.01325    0.97516667]\n",
      " [0.96516667 0.02041667 0.994     ]\n",
      " [0.21034524 0.85960516 0.07044444]\n",
      " [0.725      0.19725    0.8805    ]\n",
      " [0.96516667 0.02041667 0.994     ]\n",
      " [0.95641667 0.02479167 0.994     ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 2 2 2]\n",
      ">acc=0.889\n",
      "[[0.78835354 0.42519823 0.36125   ]\n",
      " [1.         0.06058333 0.87883333]\n",
      " [0.46028211 0.45885895 0.622     ]\n",
      " [0.19278211 0.85435895 0.0985    ]\n",
      " [0.97090909 0.12787879 0.77333333]\n",
      " [0.95666667 0.06558333 0.91216667]\n",
      " [0.99       0.005      1.        ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 0 0 2]\n",
      ">acc=0.667\n",
      "[[0.87790909 0.09745022 0.92719048]\n",
      " [1.         0.0322381  0.93552381]\n",
      " [0.98       0.04140476 0.93719048]\n",
      " [0.13713925 0.79813474 0.26659127]\n",
      " [0.95166667 0.03041667 0.9875    ]\n",
      " [0.975      0.0417381  0.94152381]\n",
      " [0.97666667 0.01166667 1.        ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[2 0 0 1 2 0 2]\n",
      ">acc=0.778\n",
      "Estimated Accuracy for random forest: 0.622 (0.247)\n",
      "Estimated Precision for random forest: 0.564 (0.265)\n",
      "Estimated Recall for random forest: 0.571 (0.239)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#load data\n",
    "data = sio.loadmat('5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "\n",
    "X = data1[:,0:5]\n",
    "y = data1[:,5]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate over splits\n",
    "outer_acc = list()\n",
    "outer_rec = list()\n",
    "outer_pre = list()\n",
    "for train_i, test_i in outer_cv.split(X, y):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_i, :], X[test_i, :]\n",
    "    y_train, y_test = y[train_i], y[test_i]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train1 = X_train[np.where((y_train==0) | (y_train==1)), :]\n",
    "    X_train1 = np.reshape(X_train1,(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y_train1 = y_train[np.where((y_train==0) | (y_train==1))]\n",
    "\n",
    "    X_train2 = X_train[np.where((y_train==1) | (y_train==2)), :]\n",
    "    X_train2 = np.reshape(X_train2,(X_train2.shape[1],X_train2.shape[2]))\n",
    "    y_train2 = y_train[np.where((y_train==1) | (y_train==2))]\n",
    "    \n",
    "    \n",
    "    # SVM model: rbf kernel\n",
    "    model1 = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "    model2 = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "    model1.fit(X_train1, y_train1)\n",
    "    model2.fit(X_train2, y_train2)\n",
    "    \n",
    "\n",
    "    # evaluate the model\n",
    "    ypred1 = model1.predict_proba(X_test)\n",
    "    ypred2 = model2.predict_proba(X_test)\n",
    "    \n",
    "    p_normal = ypred1[:,0]\n",
    "    p_mci = (ypred1[:,1]+ypred2[:,0])/2\n",
    "    p_ad = ypred2[:,1]\n",
    "    \n",
    "    p = np.array([p_normal, p_mci, p_ad]).T\n",
    "    print(p)\n",
    "    \n",
    "    y_pred = np.argmax(p, axis=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    outer_acc.append(acc)\n",
    "    outer_pre.append(pre)\n",
    "    outer_rec.append(rec)\n",
    "    print('>acc=%.3f' % (acc))\n",
    "\n",
    "# # overall estimated accuracy of the model\n",
    "print('Estimated Accuracy for random forest: %.3f (%.3f)' % (np.mean(outer_acc), np.std(outer_acc)))\n",
    "print('Estimated Precision for random forest: %.3f (%.3f)' % (np.mean(outer_pre), np.std(outer_pre)))\n",
    "print('Estimated Recall for random forest: %.3f (%.3f)' % (np.mean(outer_rec), np.std(outer_rec)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest (Normal(0) vs MCI (1) + MCI (1) vs AD (2)) with 4 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51       0.55823214 0.37353571]\n",
      " [0.953      0.05227381 0.94245238]\n",
      " [0.97166667 0.03119048 0.96595238]\n",
      " [0.05633333 0.90526786 0.13313095]\n",
      " [0.13833333 0.85576786 0.15013095]\n",
      " [0.94133333 0.04844048 0.96178571]\n",
      " [0.50466667 0.43253571 0.6302619 ]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[1 0 0 1 1 2 2]\n",
      ">acc=0.889\n",
      "[[0.59       0.22       0.97      ]\n",
      " [0.64       0.22       0.92      ]\n",
      " [0.61083333 0.55736905 0.27442857]\n",
      " [0.583      0.62057738 0.17584524]\n",
      " [0.32583333 0.74766071 0.17884524]\n",
      " [0.65       0.19066667 0.96866667]\n",
      " [0.69333333 0.51549405 0.27567857]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[2 2 0 1 1 2 0]\n",
      ">acc=0.611\n",
      "[[0.95909091 0.06665314 0.90760281]\n",
      " [0.99909091 0.00882576 0.98325758]\n",
      " [0.97409091 0.01440909 0.99709091]\n",
      " [0.30882107 0.78174639 0.12768615]\n",
      " [0.57609091 0.35590909 0.71209091]\n",
      " [0.97409091 0.01440909 0.99709091]\n",
      " [0.92284091 0.04503409 0.98709091]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 2 2 2]\n",
      ">acc=0.889\n",
      "[[0.81153968 0.40513889 0.37818254]\n",
      " [1.         0.07696429 0.84607143]\n",
      " [0.56819048 0.37749405 0.67682143]\n",
      " [0.20221825 0.83616865 0.12544444]\n",
      " [0.99       0.09640873 0.81718254]\n",
      " [0.91966667 0.1125     0.85533333]\n",
      " [0.94666667 0.0328355  0.98766234]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 0 0 2]\n",
      ">acc=0.667\n",
      "[[0.90583333 0.09489268 0.90438131]\n",
      " [0.99833333 0.04475379 0.91215909]\n",
      " [0.99833333 0.03975379 0.92215909]\n",
      " [0.16277814 0.74726569 0.34269048]\n",
      " [0.895      0.08008333 0.94483333]\n",
      " [0.92833333 0.09589268 0.87988131]\n",
      " [0.9875     0.01058333 0.99133333]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 0 1 2 0 2]\n",
      ">acc=0.889\n",
      "Estimated Accuracy for random forest: 0.789 (0.124)\n",
      "Estimated Precision for random forest: 0.771 (0.154)\n",
      "Estimated Recall for random forest: 0.743 (0.140)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#load data\n",
    "data = sio.loadmat('ML_data1.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "\n",
    "X = data1[:,0:4]\n",
    "y = data1[:,4]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate over splits\n",
    "outer_acc = list()\n",
    "outer_rec = list()\n",
    "outer_pre = list()\n",
    "for train_i, test_i in outer_cv.split(X, y):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_i, :], X[test_i, :]\n",
    "    y_train, y_test = y[train_i], y[test_i]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train1 = X_train[np.where((y_train==0) | (y_train==1)), :]\n",
    "    X_train1 = np.reshape(X_train1,(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y_train1 = y_train[np.where((y_train==0) | (y_train==1))]\n",
    "\n",
    "    X_train2 = X_train[np.where((y_train==1) | (y_train==2)), :]\n",
    "    X_train2 = np.reshape(X_train2,(X_train2.shape[1],X_train2.shape[2]))\n",
    "    y_train2 = y_train[np.where((y_train==1) | (y_train==2))]\n",
    "    \n",
    "    \n",
    "    # SVM model: rbf kernel\n",
    "    model1 = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "    model2 = RandomForestClassifier(max_depth=2, min_samples_split= 2, n_estimators= 100, random_state=0)\n",
    "    model1.fit(X_train1, y_train1)\n",
    "    model2.fit(X_train2, y_train2)\n",
    "    \n",
    "\n",
    "    # evaluate the model\n",
    "    ypred1 = model1.predict_proba(X_test)\n",
    "    ypred2 = model2.predict_proba(X_test)\n",
    "    \n",
    "    p_normal = ypred1[:,0]\n",
    "    p_mci = (ypred1[:,1]+ypred2[:,0])/2\n",
    "    p_ad = ypred2[:,1]\n",
    "    \n",
    "    p = np.array([p_normal, p_mci, p_ad]).T\n",
    "    print(p)\n",
    "    \n",
    "    y_pred = np.argmax(p, axis=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    outer_acc.append(acc)\n",
    "    outer_pre.append(pre)\n",
    "    outer_rec.append(rec)\n",
    "    print('>acc=%.3f' % (acc))\n",
    "\n",
    "# # overall estimated accuracy of the model\n",
    "print('Estimated Accuracy for random forest: %.3f (%.3f)' % (np.mean(outer_acc), np.std(outer_acc)))\n",
    "print('Estimated Precision for random forest: %.3f (%.3f)' % (np.mean(outer_pre), np.std(outer_pre)))\n",
    "print('Estimated Recall for random forest: %.3f (%.3f)' % (np.mean(outer_rec), np.std(outer_rec)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, Normal (0) vs MCI (1) vs AD (2) \n",
    "Three-class classification with 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [2, 5, 10],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [10, 100, 500, 1000]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.concatenate((Normal,MCI,AD),axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'n_estimators':[10,100,500,1000],'max_depth':[2, 5, 10], 'min_samples_split':[2,4,8]}\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "clf2 = GridSearchCV(RF, parameters)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.6571428571428571\n",
      "0.19378085666072195\n",
      "balanced_accuracy:\n",
      "0.6571428571428571\n",
      "0.19378085666072195\n"
     ]
    }
   ],
   "source": [
    "train_data = np.concatenate((Normal,MCI,AD),axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = [ 'balanced_accuracy', 'accuracy']\n",
    "model = RandomForestClassifier(max_depth=2, min_samples_split=2, n_estimators=10, random_state=0)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
