{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls /content/drive/MyDrive/5features.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.io as sio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('Importing Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('/content/drive/MyDrive/5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "Normal = data1[:15,:]\n",
    "MCI = data1[15:22,:]\n",
    "AD = data1[22:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from local address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "Normal = data1[:15,:]\n",
    "MCI = data1[15:22,:]\n",
    "AD = data1[22:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, Normal (0) vs MCI (1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 2, 10], 'gamma': [0.1, 1, 3]})"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.append(Normal,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'C':[1,2,10],'gamma':[0.1, 1, 3]}\n",
    "svc = SVC(kernel='rbf')\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics --- linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.9099999999999999\n",
      "0.11135528725660043\n",
      "balanced_accuracy:\n",
      "0.9099999999999999\n",
      "0.11135528725660043\n",
      "precision:\n",
      "0.9\n",
      "0.2\n",
      "precision macro:\n",
      "0.925\n",
      "0.1\n",
      "recall:\n",
      "0.9\n",
      "0.20000000000000004\n",
      "recall macro:\n",
      "0.9166666666666666\n",
      "0.10540925533894599\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(Normal,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = SVC(kernel = 'linear', C = 2, gamma=0.1)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics --- RBF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.8699999999999999\n",
      "0.10770329614269006\n",
      "balanced_accuracy:\n",
      "0.8699999999999999\n",
      "0.10770329614269006\n",
      "precision:\n",
      "0.8\n",
      "0.4\n",
      "precision macro:\n",
      "0.825\n",
      "0.2318404623873926\n",
      "recall:\n",
      "0.6\n",
      "0.37416573867739417\n",
      "recall macro:\n",
      "0.8\n",
      "0.18708286933869706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahaleh fatemi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nahaleh fatemi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(Normal,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = SVC(kernel = 'rbf', C = 2, gamma=1)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, AD (1) vs MCI (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 2, 10], 'gamma': [0.1, 1, 3]})"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.append(AD,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = abs(train_data[:,num_feature]-2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'C':[1,2,10],'gamma':[0.1, 1, 3]}\n",
    "svc = SVC(kernel='linear')\n",
    "clf1 = GridSearchCV(svc, parameters)\n",
    "clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics --- linear kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.8\n",
      "0.18708286933869706\n",
      "balanced_accuracy:\n",
      "0.8\n",
      "0.18708286933869706\n",
      "precision:\n",
      "0.6333333333333333\n",
      "0.3711842908553348\n",
      "precision macro:\n",
      "0.7833333333333334\n",
      "0.24494897427831783\n",
      "recall:\n",
      "0.8\n",
      "0.4\n",
      "recall macro:\n",
      "0.7833333333333333\n",
      "0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(AD,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = abs(train_data[:,num_feature]-2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = SVC(kernel = 'linear', C = 1, gamma=0.1)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and classification metrics --- RBF kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.85\n",
      "0.1224744871391589\n",
      "balanced_accuracy:\n",
      "0.85\n",
      "0.1224744871391589\n",
      "precision:\n",
      "0.8333333333333334\n",
      "0.21081851067789195\n",
      "precision macro:\n",
      "0.8833333333333332\n",
      "0.10000000000000002\n",
      "recall:\n",
      "0.9\n",
      "0.2\n",
      "recall macro:\n",
      "0.8666666666666666\n",
      "0.11303883305208781\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(AD,MCI,axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = abs(train_data[:,num_feature]-2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = ['precision_macro', 'recall_macro', 'balanced_accuracy', 'accuracy','precision','recall']\n",
    "model = SVC(kernel = 'rbf', C = 1, gamma=0.1)\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('precision:')\n",
    "print(scores['test_precision'].mean())\n",
    "print(scores['test_precision'].std())\n",
    "\n",
    "print('precision macro:')\n",
    "print(scores['test_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].std())\n",
    "\n",
    "print('recall:')\n",
    "print(scores['test_recall'].mean())\n",
    "print(scores['test_recall'].std())\n",
    "\n",
    "print('recall macro:')\n",
    "print(scores['test_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVM (Normal(0) vs MCI (1) + MCI (1) vs AD (2)) with 5 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80350599 0.25440683 0.68768036]\n",
      " [0.95346061 0.05084455 0.94485029]\n",
      " [0.94600576 0.06375111 0.92649203]\n",
      " [0.02776427 0.963727   0.04478173]\n",
      " [0.40903684 0.5662469  0.45846936]\n",
      " [0.88539949 0.08867191 0.93725669]\n",
      " [0.60061582 0.38275906 0.63386606]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[0 0 0 1 1 2 2]\n",
      ">acc=1.000\n",
      "[[0.70317005 0.25739266 0.78204462]\n",
      " [0.88496122 0.12000968 0.87501942]\n",
      " [0.70260521 0.28865316 0.72008848]\n",
      " [0.41878848 0.55029921 0.48061309]\n",
      " [0.71543627 0.28293679 0.71869016]\n",
      " [0.73613026 0.24558543 0.77269888]\n",
      " [0.90015028 0.19110385 0.71764201]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[2 0 2 1 2 2 0]\n",
      ">acc=0.444\n",
      "[[0.77262394 0.2366674  0.75404126]\n",
      " [0.89767304 0.15227313 0.7977807 ]\n",
      " [0.62125961 0.36694834 0.64484371]\n",
      " [0.34725182 0.65376395 0.34522028]\n",
      " [0.65837361 0.33817666 0.66527308]\n",
      " [0.64410708 0.34093384 0.67402524]\n",
      " [0.6215228  0.36641357 0.64565006]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 2 2 2]\n",
      ">acc=0.889\n",
      "[[0.93189002 0.23299124 0.6021275 ]\n",
      " [0.74621068 0.27276871 0.70825191]\n",
      " [0.55107828 0.29094121 0.86703931]\n",
      " [0.09123108 0.88414077 0.14048738]\n",
      " [0.93089235 0.21082745 0.64745274]\n",
      " [0.90276445 0.08864968 0.91993619]\n",
      " [0.66462067 0.23884447 0.8576904 ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 0 2 2]\n",
      ">acc=0.778\n",
      "[[0.73648769 0.17560558 0.91230114]\n",
      " [0.89398806 0.13267771 0.84065652]\n",
      " [0.89268351 0.11148106 0.88435437]\n",
      " [0.65038479 0.33150521 0.68660479]\n",
      " [0.74019355 0.24520585 0.76939474]\n",
      " [0.90068554 0.09690394 0.90550658]\n",
      " [0.72365036 0.17163514 0.93307936]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[2 0 0 2 2 2 2]\n",
      ">acc=0.556\n",
      "Estimated Accuracy for rbf SVM: 0.733 (0.206)\n",
      "Estimated Precision for rbf SVM: 0.773 (0.153)\n",
      "Estimated Recall for rbf SVM: 0.743 (0.190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahaleh fatemi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# try nested cv for rbf kernel SVM\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import scipy.io as sio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "#load data\n",
    "data = sio.loadmat('5features.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "\n",
    "X = data1[:,0:5]\n",
    "y = data1[:,5]\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate over splits\n",
    "outer_acc = list()\n",
    "outer_rec = list()\n",
    "outer_pre = list()\n",
    "for train_i, test_i in outer_cv.split(X, y):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_i, :], X[test_i, :]\n",
    "    y_train, y_test = y[train_i], y[test_i]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train1 = X_train[np.where((y_train==0) | (y_train==1)), :]\n",
    "    X_train1 = np.reshape(X_train1,(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y_train1 = y_train[np.where((y_train==0) | (y_train==1))]\n",
    "\n",
    "    X_train2 = X_train[np.where((y_train==1) | (y_train==2)), :]\n",
    "    X_train2 = np.reshape(X_train2,(X_train2.shape[1],X_train2.shape[2]))\n",
    "    y_train2 = y_train[np.where((y_train==1) | (y_train==2))]\n",
    "    \n",
    "    \n",
    "    # SVM model: rbf kernel\n",
    "    model1 = SVC(kernel = 'rbf', C=2, gamma=1, probability=True)\n",
    "    model2 = SVC(kernel = 'rbf', C=2, gamma=1, probability=True)\n",
    "    model1.fit(X_train1, y_train1)\n",
    "    model2.fit(X_train2, y_train2)\n",
    "    \n",
    "\n",
    "    # evaluate the model\n",
    "    ypred1 = model1.predict_proba(X_test)\n",
    "    ypred2 = model2.predict_proba(X_test)\n",
    "    \n",
    "    p_normal = ypred1[:,0]\n",
    "    p_mci = (ypred1[:,1]+ypred2[:,0])/2\n",
    "    p_ad = ypred2[:,1]\n",
    "    \n",
    "    p = np.array([p_normal, p_mci, p_ad]).T\n",
    "    print(p)\n",
    "    \n",
    "    y_pred = np.argmax(p, axis=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    outer_acc.append(acc)\n",
    "    outer_pre.append(pre)\n",
    "    outer_rec.append(rec)\n",
    "    print('>acc=%.3f' % (acc))\n",
    "\n",
    "# # overall estimated accuracy of the model\n",
    "print('Estimated Accuracy for rbf SVM: %.3f (%.3f)' % (np.mean(outer_acc), np.std(outer_acc)))\n",
    "print('Estimated Precision for rbf SVM: %.3f (%.3f)' % (np.mean(outer_pre), np.std(outer_pre)))\n",
    "print('Estimated Recall for rbf SVM: %.3f (%.3f)' % (np.mean(outer_rec), np.std(outer_rec)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVM (Normal(0) vs MCI (1) + MCI (1) vs AD (2)) with 4 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77409392 0.30927244 0.6073612 ]\n",
      " [0.87047688 0.13071043 0.86810227]\n",
      " [0.91351822 0.09484259 0.89679659]\n",
      " [0.36508263 0.64984055 0.33523628]\n",
      " [0.46547925 0.60252319 0.32947438]\n",
      " [0.87924028 0.10894228 0.90287516]\n",
      " [0.52424609 0.43895588 0.59784215]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[0 0 0 1 1 2 2]\n",
      ">acc=1.000\n",
      "[[0.64274105 0.20537015 0.94651865]\n",
      " [0.87820409 0.09899523 0.92380546]\n",
      " [0.61823942 0.42820531 0.52534997]\n",
      " [0.15624552 0.81100392 0.22174663]\n",
      " [0.44787864 0.62345666 0.30520804]\n",
      " [0.59954816 0.27469028 0.85107127]\n",
      " [0.87290413 0.34506646 0.43696295]]\n",
      "[0. 0. 0. 1. 1. 2. 2.]\n",
      "[2 2 0 1 1 2 0]\n",
      ">acc=0.611\n",
      "[[0.94703503 0.107797   0.83737098]\n",
      " [0.96449504 0.07906405 0.87737685]\n",
      " [0.94763688 0.102245   0.84787312]\n",
      " [0.24076608 0.67604454 0.40714484]\n",
      " [0.82206894 0.1772309  0.82346927]\n",
      " [0.96943011 0.07947013 0.87162963]\n",
      " [0.94100866 0.10303477 0.8529218 ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 0 1 2 0 0]\n",
      ">acc=0.778\n",
      "[[0.75337721 0.35877523 0.52907233]\n",
      " [0.93906059 0.10668772 0.84756398]\n",
      " [0.36706277 0.53729351 0.55835021]\n",
      " [0.25346806 0.68919452 0.36814289]\n",
      " [0.79600855 0.27830997 0.64737152]\n",
      " [0.90713959 0.10637539 0.88010963]\n",
      " [0.93247522 0.08215426 0.90321627]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 2 1 0 0 0]\n",
      ">acc=0.556\n",
      "[[0.779118   0.22475669 0.77136862]\n",
      " [0.9272579  0.0853225  0.90209711]\n",
      " [0.91894896 0.08313583 0.91477938]\n",
      " [0.26877126 0.84585874 0.03951126]\n",
      " [0.89092629 0.07777857 0.95351656]\n",
      " [0.84744945 0.12869491 0.89516074]\n",
      " [0.90900865 0.06880347 0.9533844 ]]\n",
      "[0. 0. 0. 1. 2. 2. 2.]\n",
      "[0 0 0 1 2 2 2]\n",
      ">acc=1.000\n",
      "Estimated Accuracy for rbf SVM: 0.789 (0.187)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import scipy.io as sio\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#load data\n",
    "data = sio.loadmat('ML_data1.mat')\n",
    "data1 = np.asarray(data['data'])\n",
    "\n",
    "X = data1[:,0:4]\n",
    "y = data1[:,4]\n",
    "\n",
    "\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle=True, random_state=1)\n",
    "\n",
    "# enumerate over splits\n",
    "outer_results = list()\n",
    "for train_i, test_i in outer_cv.split(X, y):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_i, :], X[test_i, :]\n",
    "    y_train, y_test = y[train_i], y[test_i]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train1 = X_train[np.where((y_train==0) | (y_train==1)), :]\n",
    "    X_train1 = np.reshape(X_train1,(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y_train1 = y_train[np.where((y_train==0) | (y_train==1))]\n",
    "\n",
    "    X_train2 = X_train[np.where((y_train==1) | (y_train==2)), :]\n",
    "    X_train2 = np.reshape(X_train2,(X_train2.shape[1],X_train2.shape[2]))\n",
    "    y_train2 = y_train[np.where((y_train==1) | (y_train==2))]\n",
    "    \n",
    "    \n",
    "    # SVM model: rbf kernel\n",
    "    model1 = SVC(kernel = 'rbf', C=1, gamma=0.1, probability=True)\n",
    "    model2 = SVC(kernel = 'rbf',  C=1, gamma=0.1,probability=True)\n",
    "    model1.fit(X_train1, y_train1)\n",
    "    model2.fit(X_train2, y_train2)\n",
    "    \n",
    "\n",
    "    # evaluate the model\n",
    "    ypred1 = model1.predict_proba(X_test)\n",
    "    ypred2 = model2.predict_proba(X_test)\n",
    "    \n",
    "    p_normal = ypred1[:,0]\n",
    "    p_mci = (ypred1[:,1]+ypred2[:,0])/2\n",
    "    p_ad = ypred2[:,1]\n",
    "    \n",
    "    p = np.array([p_normal, p_mci, p_ad]).T\n",
    "    print(p)\n",
    "    \n",
    "    y_pred = np.argmax(p, axis=1)\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    outer_results.append(acc)\n",
    "    print('>acc=%.3f' % (acc))\n",
    "\n",
    "# # overall estimated accuracy of the model\n",
    "print('Estimated Accuracy for rbf SVM: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of RBF SVM with 4 features (accuracy, precision, recall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Accuracy for rbf SVM: 0.789 (0.187)\n",
      "Estimated Precision for rbf SVM: 0.748 (0.263)\n",
      "Estimated Recall for rbf SVM: 0.743 (0.229)\n"
     ]
    }
   ],
   "source": [
    "outer_acc = list()\n",
    "outer_pre = list()\n",
    "outer_rec = list()\n",
    "y_test = [0, 0, 0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 0, 1, 2, 2, 2]\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "outer_acc.append(acc)\n",
    "outer_pre.append(pre)\n",
    "outer_rec.append(rec)\n",
    "\n",
    "y_test = [0, 0, 0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 1, 0, 0, 0]\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "outer_acc.append(acc)\n",
    "outer_pre.append(pre)\n",
    "outer_rec.append(rec)\n",
    "\n",
    "\n",
    "y_test = [0, 0, 0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 0, 1, 2, 0, 0]\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "outer_acc.append(acc)\n",
    "outer_pre.append(pre)\n",
    "outer_rec.append(rec)\n",
    "\n",
    "\n",
    "y_test = [0, 0, 0, 1, 1, 2, 2]\n",
    "y_pred = [2, 2, 0, 1, 1, 2, 0]\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "outer_acc.append(acc)\n",
    "outer_pre.append(pre)\n",
    "outer_rec.append(rec)\n",
    "\n",
    "\n",
    "y_test = [0, 0, 0, 1, 1, 2, 2]\n",
    "y_pred = [0, 0, 0, 1, 1, 2, 2]\n",
    "acc = balanced_accuracy_score(y_test, y_pred)\n",
    "pre = precision_score(y_test, y_pred, average='weighted')\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "outer_acc.append(acc)\n",
    "outer_pre.append(pre)\n",
    "outer_rec.append(rec)\n",
    "\n",
    "print('Estimated Accuracy for rbf SVM: %.3f (%.3f)' % (np.mean(outer_acc), np.std(outer_acc)))\n",
    "print('Estimated Precision for rbf SVM: %.3f (%.3f)' % (np.mean(outer_pre), np.std(outer_pre)))\n",
    "print('Estimated Recall for rbf SVM: %.3f (%.3f)' % (np.mean(outer_rec), np.std(outer_rec)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search, Normal (0) vs MCI (1) vs AD (2)\n",
    "Three-class classification with 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(decision_function_shape='ovo'),\n",
       "             param_grid={'C': [1, 2, 10], 'gamma': [0.1, 1, 3]})"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.concatenate((Normal,MCI,AD),axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "parameters = {'C':[1,2,10],'gamma':[0.1, 1, 3]}\n",
    "svc = SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "clf2 = GridSearchCV(svc, parameters)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.6571428571428571\n",
      "0.17142857142857143\n",
      "balanced_accuracy:\n",
      "0.6571428571428571\n",
      "0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "train_data = np.concatenate((Normal,MCI,AD),axis=0)\n",
    "num_feature = 5\n",
    "X = train_data[:,0:num_feature]\n",
    "y = train_data[:,num_feature]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "scoring = [ 'balanced_accuracy', 'accuracy']\n",
    "model = SVC(kernel = 'rbf', C = 1, gamma=0.1, decision_function_shape='ovo')\n",
    "scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print('accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "print('balanced_accuracy:')\n",
    "print(scores['test_accuracy'].mean())\n",
    "print(scores['test_accuracy'].std())\n",
    "\n",
    "# print('precision:')\n",
    "# print(scores['test_precision'].mean())\n",
    "# print(scores['test_precision'].std())\n",
    "\n",
    "# print('precision macro:')\n",
    "# print(scores['test_precision_macro'].mean())\n",
    "# print(scores['test_precision_macro'].std())\n",
    "\n",
    "# print('recall:')\n",
    "# print(scores['test_recall'].mean())\n",
    "# print(scores['test_recall'].std())\n",
    "\n",
    "# print('recall macro:')\n",
    "# print(scores['test_recall_macro'].mean())\n",
    "# print(scores['test_recall_macro'].std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
